{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''_¯\\_(ツ)_/¯_\n",
    "''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "prediction.plot(x=0,y=2,kind='scatter',s = list(prediction['Res']),c=2,figsize=(15,10))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def cv_score(model,predictor,target):\n",
    "    from sklearn.cross_validation import cross_val_score\n",
    "    return -cross_val_score(model,predictor,target,cv=10,scoring = 'mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat_var= train.select_dtypes(include = ['object']).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_var = train.select_dtypes(include = ['int64','float64']).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# list all functions in a module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import inspect\n",
    "all_functions = inspect.getmembers(module, inspect.isfunction)\n",
    "all_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plot with annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#### First let's create a dataset called X, with 6 records and 2 features each.\n",
    "X = np.array([[-1, 2], [4, -4], [-2, 1], [-1, 3], [-3, 2], [-1, 4]])\n",
    "\n",
    "#### Next we will instantiate a nearest neighbor object, and call it nbrs. Then we will fit it to dataset X.\n",
    "nbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(X)\n",
    "\n",
    "#### Let's find the k-neighbors of each point in object X. To do that we call the kneighbors() function on object X.\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "#### Let's print out the indices of neighbors for each record in object X.\n",
    "indices\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.scatter(X.transpose()[0],X.transpose()[1],cmap=plt.get_cmap('Spectral'))\n",
    "labels = ['point{0}'.format(i) for i in range(len(X))]\n",
    "for label, x, y in zip(labels,X.transpose()[0],X.transpose()[1]):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(-20, 20),size=14,\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Histogram and KDE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = train.MMAX.plot(kind='hist')\n",
    "train.MMAX.plot(kind='kde', ax=ax, secondary_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Correlation frame >0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pandas import Int64Index\n",
    "data_corr = data.corr().unstack()['count'].to_dict()\n",
    "count_corr=pd.DataFrame(data_corr.items(),columns={'features','corr'})\n",
    "#print  count_corr['features'][count_corr['corr'] > 0.2]\n",
    "count_corr[((count_corr['corr']<-0.2)|(count_corr['corr']>0.2)) & (count_corr['corr'] < 1.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "# Ratio of non-null\n",
    "print(1.0 * data.count().sum() / data.size)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.columns[pd.isnull(data).sum() > 0] # data.columns[pd.isnull(data).any()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Null Columns with Null values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "null_coll=data.columns[pd.isnull(data).any()].values.tolist()\n",
    "for i in null_coll:\n",
    "    print i,' - ',len(data[data[i].isnull()])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows with null value in any column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data[pd.isnull(data).sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rows with null value in specific column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data[pd.isnull(data[['Age']]).sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rows around null valuein specific column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x=data[pd.isnull(data[['Age']]).sum(axis=1) > 0].index.tolist()\n",
    "z=[[i-1,i,i+1] for i in x]\n",
    "z=np.ndarray.flatten(np.array(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill na with moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x=data[pd.isnull(data[['Col']]).sum(axis=1) > 0].index.tolist()\n",
    "z=[[i,i-1,i+1] for i in x]\n",
    "for i in z:\n",
    "    data= data.set_value(i[0],'Col',data['Col'].iloc[i[1:]].mean())\n",
    "z=np.ndarray.flatten(np.array(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TwoPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def twoplot(df, col, xaxis=None):\n",
    "    ''' scatter plot a feature split into response values as two subgraphs '''\n",
    "    if col not in df.columns.values:\n",
    "        print('ERROR: %s not a column' % col)\n",
    "    ndf = pd.DataFrame(index = df.index)\n",
    "    ndf[col] = df[col]\n",
    "    ndf[xaxis] = df[xaxis] if xaxis else df.index\n",
    "    ndf['survivedno'] = df['survivedno']\n",
    "    \n",
    "    g = sns.FacetGrid(ndf, col=\"survivedno\", hue=\"survivedno\")\n",
    "    g.map(plt.scatter, xaxis, col, alpha=.7, s=1)\n",
    "    g.add_legend();\n",
    "    \n",
    "    del ndf\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To get correlated feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def corrlist(data):\n",
    "    feat=data.columns.tolist()\n",
    "    corrmat=np.array(data.corr())\n",
    "    for i in range(len(corrmat)):\n",
    "        for j in range(len(corrmat)):\n",
    "            if j>i :\n",
    "                corrmat[i][j]=2\n",
    "    corrFrame= pd.DataFrame(pd.DataFrame(corrmat,columns=feat,index=feat).unstack()).reset_index()\n",
    "    print plt.matshow(corrmat)\n",
    "    del corrmat\n",
    "    corrFrame=corrFrame[corrFrame[0]<=1].rename(columns={0:'corr'})\n",
    "    return corrFrame\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt    \n",
    "import xgboost as xgb\n",
    "iv=['np'\t, 'os'\t ,'pd'\t, 'plt'\t ,'tqdm'\t, 'train'\t ,'train_date'\t, 'train_date_num'\t, 'train_num'\t ]\n",
    "def memchk(iv):\n",
    "    import sys,operator\n",
    "    ipython_vars=iv\n",
    "    ,'warnings'\t, 'xgboost']\n",
    "    print sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "    return sorted([{i:sys.getsizeof(globals().get(i))/1000000.0} for i in ipython_vars])\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "%load_ext autotime\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "plt.style.use('classic')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "import math\n",
    "from collections import Counter\n",
    "def get_cosine(vec1, vec2):\n",
    "    common = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in common])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()]) \n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()]) \n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "   \n",
    "    if not denominator:\n",
    "        return 0.0 \n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text): \n",
    "    words = text.split() \n",
    "    return Counter(words)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "clf = LogisticRegression()\n",
    "grid = {\n",
    "    'C': [1e-6, 1e-3, 1e0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'class_weight':['balanced',None]\n",
    "}\n",
    "cv = GridSearchCV(clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "for i in range(1, len(cv.cv_results_['params'])+1):\n",
    "    rank = cv.cv_results_['rank_test_score'][i-1]\n",
    "    s = cv.cv_results_['mean_test_score'][i-1]\n",
    "    sd = cv.cv_results_['std_test_score'][i-1]\n",
    "    params = cv.cv_results_['params'][i-1]\n",
    "    print(\"{0}. Mean validation neg log loss: {1:.3f} (std: {2:.3f}) - {3}\".format(\n",
    "        rank,\n",
    "        s,\n",
    "        sd,\n",
    "        params\n",
    "    ))\n",
    "    \n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "colors = ['r', 'g', 'b', 'y', 'k', 'c', 'm', 'brown', 'r']\n",
    "lw = 1\n",
    "Cs = [1e-6, 1e-4, 1e0]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for different classifiers')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "labels = []\n",
    "for idx, C in enumerate(Cs):\n",
    "    clf = LogisticRegression(C = C,penalty='l1',class_weight ='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"C: {}, parameters {} and intercept {}\".format(C, clf.coef_, clf.intercept_))\n",
    "    fpr, tpr, _ = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=lw, color=colors[idx])\n",
    "    labels.append(\"C: {}, AUC = {}\".format(C, np.round(roc_auc, 4)))\n",
    "\n",
    "plt.legend(['random AUC = 0.5'] + labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Decision Tree\n",
    "```python\n",
    "def show_tree(decisionTree,feat):\n",
    "    from sklearn.tree import export_graphviz\n",
    "    from scipy import misc\n",
    "    import matplotlib.pyplot as plt\n",
    "    dotfile = open('dtree.dot', 'w')\n",
    "    export_graphviz(clf.tree_, out_file = dotfile, feature_names =feat)\n",
    "    dotfile.close()\n",
    "    from subprocess import check_call\n",
    "    check_call(['dot','-Tpng','dtree.dot','-o','dtree.png'])\n",
    "    i = misc.imread('dtree.png')\n",
    "    plt.figure(figsize=(20,18))\n",
    "    plt.imshow(i)\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Split Text into Rows-\n",
    "```python\n",
    "b = pd.DataFrame(temp.text.str.split().tolist(), index=temp.file_id).stack()\n",
    "b = b.reset_index()[[0, 'file_id']] # var1 variable is currently labeled 0\n",
    "b.columns = ['text', 'file_id'] \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
